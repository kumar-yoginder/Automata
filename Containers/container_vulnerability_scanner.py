#!/usr/bin/env python3
import os
import re
import sys
import csv
import time
import glob
import json
import requests
import argparse
import subprocess
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup

# Define stages
STAGES = ["scan", "nvd_enrich", "report"]

CACHE = {}  # cache CVEs

TRIVY_TEMPLATE = "csv.tpl"
GRYPE_TEMPLATE = "csv_base.tmpl"

NVD_API_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
NVD_API_KEY = os.getenv("NVD_API_KEY","")  # Optional, from environment variable
HEADERS = {"apiKey": NVD_API_KEY} if NVD_API_KEY else {}

TRIVY_URL = "https://raw.githubusercontent.com/aquasecurity/vim-trivy/refs/heads/master/csv.tpl"
GRYPE_URL = "https://raw.githubusercontent.com/anchore/grype/refs/heads/main/templates/csv.tmpl"

def get_severity(cve_id, df):
    match = df[df["Vulnerability ID"] == cve_id]
    return match["Severity"].values[0].title() if not match.empty else "Unknown".title()

# Combine packages and versions
def aggregate_column(df, col):
    return (
        df.groupby("Vulnerability ID")[col]
        .apply(lambda x: ",".join(sorted(set(x.dropna()))))
    )

def severity_priority(sev):
    order = {"Critical": 1, "High": 2, "Medium": 3, "Low": 4, "Unknown": 5, "N/A": 6}
    return order.get(sev, 7)

def load_cve_cache(cache_path):
    if os.path.isfile(cache_path):
        try:
            with open(cache_path, "r") as f:
                return json.load(f)
        except Exception as e:
            print(f"[!] Failed to load cache: {e}")
    return {}

def save_cve_cache(cache, cache_path):
    try:
        with open(cache_path, "w") as f:
            json.dump(cache, f, indent=2)
        print(f"[+] CVE cache saved to: {cache_path}")
    except Exception as e:
        print(f"[!] Failed to save CVE cache: {e}")

def check_nvd_enriched_outputs(images, output_dir):
    all_exist = True
    for image in images:
        safe_name = sanitize_filename(image)
        grype_file = os.path.join(output_dir, f"{safe_name}_grype_nvd_enriched.csv")
        trivy_file = os.path.join(output_dir, f"{safe_name}_trivy_nvd_enriched.csv")

        if not os.path.isfile(grype_file):
            print(f"[!] Missing NVD-enriched file: {grype_file}")
            all_exist = False
        if not os.path.isfile(trivy_file):
            print(f"[!] Missing NVD-enriched file: {trivy_file}")
            all_exist = False

    return all_exist

def check_previous_scan_outputs(images, output_dir):
    all_exist = True
    for image in images:
        safe_name = sanitize_filename(image)
        grype_file = os.path.join(output_dir, f"{safe_name}_grype.csv")
        trivy_file = os.path.join(output_dir, f"{safe_name}_trivy.csv")

        if not os.path.isfile(grype_file):
            print(f"[!] Missing: {grype_file}")
            all_exist = False
        if not os.path.isfile(trivy_file):
            print(f"[!] Missing: {trivy_file}")
            all_exist = False

    return all_exist

def generate_stats_sheet(grype_df, trivy_df):
    # Unique CVE sets per tool
    grype_cves = set(grype_df["Vulnerability ID"].dropna())
    trivy_cves = set(trivy_df["Vulnerability ID"].dropna())
    all_cves = grype_cves.union(trivy_cves)

    # Base summary structure
    summary = pd.DataFrame({"Vulnerability ID": list(all_cves)})
    summary["In Grype"] = summary["Vulnerability ID"].isin(grype_cves)
    summary["In Trivy"] = summary["Vulnerability ID"].isin(trivy_cves)
    summary["Present in all scans"] = summary["In Grype"] & summary["In Trivy"]

    merged_df = pd.concat([grype_df, trivy_df])
    summary["Package Name"] = summary["Vulnerability ID"].map(
        aggregate_column(merged_df, "Package")
    )
    summary["Version"] = summary["Vulnerability ID"].map(
        aggregate_column(merged_df, "Version Installed")
    )

    # Enrichment Fields
    enriched_cols = ["NVD_Severity", "NVD_CVSS_Version", "NVD_CVSS_Score", "Generation date"]

    for col in enriched_cols:
        if col in merged_df.columns:
            if col == "NVD_Severity":
                mapping = (
                    merged_df[["Vulnerability ID", col]]
                    .dropna()
                    .groupby("Vulnerability ID")[col]
                    .apply(lambda x: sorted(set(x), key=severity_priority)[0])
                )
            elif col == "NVD_CVSS_Version":
                mapping = (
                    merged_df[["Vulnerability ID", col]]
                    .dropna()
                    .groupby("Vulnerability ID")[col]
                    .apply(lambda x: next((v for v in x if v and v != "N/A"), "N/A"))
                )
            else:
                mapping = (
                    merged_df[["Vulnerability ID", col]]
                    .dropna()
                    .groupby("Vulnerability ID")[col]
                    .first()
                )

            summary[col] = summary["Vulnerability ID"].map(mapping).fillna("N/A")
        else:
            summary[col] = "N/A"

    tools = ["Grype", "Trivy", "All"]
    severity_levels = ["Critical", "High", "Medium", "Low", "Unknown"]
    severity_table = {tool: {level: 0 for level in severity_levels} for tool in tools}

    for _, row in summary.iterrows():
        cve = row["Vulnerability ID"]
        if row["In Grype"] and row["In Trivy"]:
            sev = get_severity(cve, trivy_df)
            severity_table["All"][sev] = severity_table["All"].get(sev, 0) + 1
            severity_table["Grype"][sev] = severity_table["Grype"].get(sev, 0) + 1
            severity_table["Trivy"][sev] = severity_table["Trivy"].get(sev, 0) + 1
        else:
            if row["In Grype"]:
                sev = get_severity(cve, grype_df)
                severity_table["All"][sev] = severity_table["All"].get(sev, 0) + 1
                severity_table["Grype"][sev] = severity_table["Grype"].get(sev, 0) + 1
            if row["In Trivy"]:
                sev = get_severity(cve, trivy_df)
                severity_table["All"][sev] = severity_table["All"].get(sev, 0) + 1
                severity_table["Trivy"][sev] = severity_table["Trivy"].get(sev, 0) + 1
        
    severity_counts = pd.DataFrame([
        {"Tool (Unique Count Only)": tool, **counts} for tool, counts in severity_table.items()
    ])[["Tool (Unique Count Only)"] + severity_levels]

    return summary, severity_counts

def generate_xlsx_report(output_dir):
    print("[+] Generating Excel report...")

    grype_files = glob.glob(os.path.join(output_dir, "*_grype_nvd_enriched.csv"))
    trivy_files = glob.glob(os.path.join(output_dir, "*_trivy_nvd_enriched.csv"))

    all_grype = pd.concat([pd.read_csv(f) for f in grype_files], ignore_index=True) if grype_files else pd.DataFrame()
    all_trivy = pd.concat([pd.read_csv(f) for f in trivy_files], ignore_index=True) if trivy_files else pd.DataFrame()

    report_path = os.path.join(output_dir, "vulnerability_report.xlsx")
    with pd.ExcelWriter(report_path, engine='openpyxl') as writer:
        if not all_grype.empty:
            all_grype.to_excel(writer, sheet_name="grype", index=False)
        if not all_trivy.empty:
            all_trivy.to_excel(writer, sheet_name="trivy", index=False)

        # STATS Sheet
        stats_df1, stats_df2 = generate_stats_sheet(all_grype, all_trivy)
        stats_df1.to_excel(writer, sheet_name="Over All Statistics", index=False)
        stats_df2.to_excel(writer, sheet_name="Statistics", index=False)

    print(f"[+] Report saved at: {report_path}")

def query_nvd(cve_id):
    params = {"cveId": cve_id}
    try:
        response = requests.get(NVD_API_URL, headers=HEADERS, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        vuln = data.get("vulnerabilities", [{}])[0].get("cve", {})
        metrics = vuln.get("metrics", {})

        # Try CVSS v3.1 first, then fallback
        for version in ["cvssMetricV31", "cvssMetricV30", "cvssMetricV2"]:
            if version in metrics:
                score_data = metrics[version][0]["cvssData"]
                return {
                    "NVD_CVSS_Version": version,
                    "NVD_CVSS_Score": score_data["baseScore"],
                    "NVD_Severity": score_data["baseSeverity"]
                }
        return {"NVD_CVSS_Version": "N/A", "NVD_CVSS_Score": "N/A", "NVD_Severity": "N/A"}
    except Exception as e:
        print(f"[!] Error fetching {cve_id} from NVD: {e}")
        return {"NVD_CVSS_Version": "N/A", "NVD_CVSS_Score": "N/A", "NVD_Severity": "N/A"}
    
def extract_cve_id(ghsa_id):
    url = f"https://github.com/advisories/{ghsa_id}"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        for a in soup.find_all('a', href=True):
            if 'CVE-' in a.text:
                return a.text.strip()
    except Exception as e:
        print(f"Failed to fetch {ghsa_id}: {e}")
    return ghsa_id  # fallback if CVE not found

def enrich_csv_with_nvd(input_csv, output_csv):
    global CACHE  # cache CVEs
    enriched_rows = []
    date_now = datetime.now().strftime("%d/%b/%Y")

    with open(input_csv, newline='') as infile:
        reader = csv.DictReader(infile)
        fieldnames = reader.fieldnames + ["NVD_Severity", "NVD_CVSS_Version", "NVD_CVSS_Score", "Generation date"]

        for row in reader:
            cve = row.get("Vulnerability ID", "").strip()
            cve = extract_cve_id(cve) if cve and cve.startswith("GHSA") else cve
            row["Vulnerability ID"] = cve
            if not cve:
                continue    
            if cve not in CACHE:
                CACHE[cve] = query_nvd(cve)
                time.sleep(0.7 if NVD_API_KEY else 1.5)
            row.update(CACHE[cve])
            row["Generation date"] = date_now
            enriched_rows.append(row)
    with open(output_csv, "w", newline='') as outfile:
        writer = csv.DictWriter(outfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(enriched_rows)
    print(f"[+] Enriched CSV saved: {os.path.basename(output_csv)}")

def enrich_with_nvd_data(output_dir):
    for csv_file in os.listdir(output_dir):
        input_csv = os.path.join(output_dir, csv_file)
        output_csv = os.path.join(output_dir, f"{csv_file.split('.csv')[0]}_nvd_enriched.csv")
        if os.path.exists(output_csv):
            print(f"[!] Skipping  {os.path.basename(output_csv)}: allraedy present.")
            continue
        elif not csv_file.endswith(("_trivy.csv", "_grype.csv")):
            continue
        print(f"[+] Enriching {os.path.basename(output_csv)} results using NVD API...")
        enrich_csv_with_nvd(input_csv, output_csv)

def sanitize_filename(image_name):
    match = re.match(r'^.+\/([^\/:]+)\/\d+(?:\.\d+)*:\d+(?:\.\d+)*$', image_name)
    return match.group(1) if match else image_name.replace("/", "_").replace(":", "_")

def scan_images_with_tools(images, output_dir):
    for image in images:
        print(f"[+] Scanning image: {image}")
        safe_name = sanitize_filename(image)

        # TRIVY
        trivy_output_path = os.path.join(output_dir, f"{safe_name}_trivy.csv")
        trivy_cmd = [
            "trivy", "image",
            "--timeout", "20m",
            "--scanners", "vuln",
            "--format", "template",
            "--template", f"@./{TRIVY_TEMPLATE}",
            "-o", trivy_output_path,
            image
        ]
        try:
            print(f"    Running Trivy scan...")
            subprocess.run(trivy_cmd, check=True)
        except subprocess.CalledProcessError:
            print(f"[!] Trivy scan failed for {image}")

        # GRYPE
        grype_output_path = os.path.join(output_dir, f"{safe_name}_grype.csv")
        grype_cmd = f"grype docker:{image} --scope all-layers -o template -t ./{GRYPE_TEMPLATE} > {grype_output_path}"
        try:
            print(f"    Running Grype scan...")
            subprocess.run(grype_cmd, shell=True, check=True, executable="/bin/bash")
        except subprocess.CalledProcessError:
            print(f"[!] Grype scan failed for {image}")

def download_file_if_missing(filename, url):
    if not os.path.isfile(filename):
        print(f"[+] Template '{filename}' not found. Downloading from {url}...")
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            with open(filename, "wb") as f:
                f.write(response.content)
            print(f"    Downloaded '{filename}' successfully.")
        except requests.RequestException as e:
            print(f"[!] Failed to download '{filename}': {e}")
            raise

def ensure_output_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Container Vulnerability Scanner using Grype and Trivy with enrichment and reporting"
    )
    parser.add_argument(
        "--images", "-i", 
        required=True,
        help="Comma-separated list of container images with tags (e.g., nginx:latest,ubuntu:22.04)"
    )
    parser.add_argument(
        "--output-dir", "-o",
        default="./output",
        help="Directory to store generated CSV and XLSX files (default: ./output)"
    )
    parser.add_argument(
        "--stage", "-s",
        choices=STAGES,
        default="scan",
        help="Stage to resume from (default: scan). Options: scan, nvd_enrich, report"
    )
    return parser.parse_args()

def main():
    global CACHE
    args = parse_arguments()
    start_stage = args.stage
    output_dir = args.output_dir
    cve_cache_path = os.path.join(output_dir, "cve_cache.json")
    images = [img.strip() for img in args.images.split(",")]
    CACHE = load_cve_cache(cve_cache_path)
    
    ensure_output_dir(output_dir)
    download_file_if_missing(TRIVY_TEMPLATE, TRIVY_URL)
    download_file_if_missing(GRYPE_TEMPLATE, GRYPE_URL)

    # Stage-based flow
    if start_stage == "scan":
        print("[+] Starting scan stage...")
        scan_images_with_tools(images, output_dir)
        enrich_with_nvd_data(output_dir)
        generate_xlsx_report(output_dir)

    elif start_stage == "nvd_enrich":
        print("[+] Resuming from NVD enrichment stage...")
        if not check_previous_scan_outputs(images, output_dir):
            print("[-] Missing scan output files. Please run with '--stage scan' first.")
            sys.exit(1)
        enrich_with_nvd_data(output_dir)
        generate_xlsx_report(output_dir)

    elif start_stage == "report":
        print("[+] Generating final XLSX report...")
        if not check_nvd_enriched_outputs(images, output_dir):
            print("[-] Missing NVD-enriched files. Run '--stage nvd_enrich' first.")
            sys.exit(1)
        generate_xlsx_report(output_dir)

    # Before exiting
    save_cve_cache(CACHE, cve_cache_path)

if __name__ == "__main__":
    main()
